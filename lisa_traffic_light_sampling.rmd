---
title: "R Notebook"
#output: html_notebook
---

#R Notebook, using keras to build convolutional neural networks for Image Classification. 

#CAP-6619
## Traffic signal classification with CNN using cost-proportionate rejection sampling
```{r}

  org_train_image_dir <- "lisa_traffic_light_train"
  org_test_image_dir <- "lisa_traffic_light_test"
  tlclass = c('go', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft')
  test_dir = "lisa_traffic_light_base/test"
  
  tlclass_size_train = length(list.files(path=org_train_image_dir))
  tlclass_size_test = length(list.files(path=org_test_image_dir))
  tlclass_size_train.byclass = sapply(tlclass, function(x) length(list.files(path=org_train_image_dir, pattern = paste0(x,"\\."))))
  tlclass_size_test.byclass = sapply(tlclass, function(x) length(list.files(path=org_test_image_dir, pattern = paste0(x,"\\."))))
  
  paste0("Total training images: ", tlclass_size_train, ", total by class: ", sum(tlclass_size_train.byclass))
  tlclass_size_train.byclass
  paste0("Total testing images: ", tlclass_size_test, ", total by class: ", sum(tlclass_size_test.byclass))
  tlclass_size_test.byclass

createTrainFolder <- function(newBaseDirName)
{
  newbasedir<-newBaseDirName
  
  dir.create(newbasedir)
  
  train_dir <- file.path(newbasedir, "train")
  dir.create(train_dir)
  
  # validation_dir <- file.path(newbasedir, "validation")
  # dir.create(validation_dir)
  
  # test_dir <- file.path(newbasedir, "test")
  # dir.create(test_dir)
  
  train_tlclass_dir <- sapply(tlclass,function(x) file.path(train_dir,x))
  sapply(train_tlclass_dir,dir.create)
  
  # validation_tlclass_dir <- sapply(tlclass,function(x) file.path(validation_dir,x))
  # sapply(validation_tlclass_dir,dir.create)
  
  # test_tlclass_dir <- sapply(tlclass,function(x) file.path(test_dir,x))
  # sapply(test_tlclass_dir,dir.create)
  
  return (list(traindir = train_dir, traindir.byclass = train_tlclass_dir))
}
```

```{r}
set.seed(0)
#train_percent <- 0.80
#validation_percent <- 0.20
#test_percent <- 0.05/

cost.byclass = sapply(tlclass_size_train.byclass, function(x) (tlclass_size_train / x))
cost.byclass = cost.byclass^0.5
Z = max(cost.byclass)

newbasedirName<-"lisa_traffic_light_sampling"
tlclass_size_train.subtotal = 0
modelNum = 1

while (tlclass_size_train.subtotal < tlclass_size_train){
  if ( modelNum == 1){
    dirlist = createTrainFolder(paste0(newbasedirName,"_",modelNum))
  }else{
    dirlist = rbind(dirlist, createTrainFolder(paste0(newbasedirName,"_",modelNum)))
  }
  for (i in 1:length(tlclass)){
    
    acceptProb = cost.byclass[i]/Z
    for (j in 1:tlclass_size_train.byclass[i]){
      if (runif(1) <= acceptProb){
        fnames <- paste0(tlclass[i], ".", j, ".jpg")
        if (modelNum == 1){
          file.copy(file.path(org_train_image_dir, fnames), 
                file.path(dirlist$traindir.byclass[i]))
          tlclass_size_train.subtotal = tlclass_size_train.subtotal + 1
        }else{
          file.copy(file.path(org_train_image_dir, fnames), 
                file.path(dirlist[modelNum,]$traindir.byclass[i]))
          tlclass_size_train.subtotal = tlclass_size_train.subtotal + 1
        }
      }
    }
  }
  modelNum = modelNum + 1
}
```

```{r}
# train_image_num = length(list.files(path=train_dir, recursive = TRUE))
# validation_image_num = length(list.files(path=validation_dir, recursive = TRUE))
# test_image_num = length(list.files(path=test_dir, recursive = TRUE))
# paste0("Number of training images: ", train_image_num, " , number of validation images: ", validation_image_num,
#        " , number of test images: ", test_image_num)
```

```{r}
# library("jpeg")
# 
# fnames <- paste0(train_cats_dir,"/","cat.", 1, ".jpg")
# jj <- readJPEG(fnames,native=TRUE)
# plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
# rasterImage(jj,0,0,1,1)
# 
# ```
# ```{r}
# cats_names <- paste0(train_cats_dir,"/","cat.", 1:3, ".jpg")
# dogs_names <- paste0(train_dogs_dir,"/","dog.", 1:3, ".jpg")
# cats_and_dogs<-c(cats_names,dogs_names)
# 
# showonejpeg<-function(file_name)
# {
#   f_jpg<-readJPEG(file_name,native=TRUE)
#   plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
#   rasterImage(f_jpg,0,0,1,1)
# }
# 
# lapply(cats_and_dogs,showonejpeg)
```


```{r}
library(keras)
# network <- keras_model_sequential() %>%
#     layer_conv_2d(filters = 32, kernel_size = c(7, 7), activation = "relu",
#     input_shape = c(48, 48, 3)) %>%
#     layer_max_pooling_2d(pool_size = c(2, 2)) %>%
#     layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
#     layer_max_pooling_2d(pool_size = c(2, 2)) %>%
#     layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
#     layer_flatten() %>%
#     layer_dense(units = 256, activation = "relu") %>%
#     layer_dropout(0.5) %>%
#     layer_dense(units = 128, activation = "relu") %>%
#     layer_dropout(0.5) %>%
#     layer_dense(units = 6, activation = "softmax")
# summary(network)
```

```{r}


# network %>% compile(
#     loss = "categorical_crossentropy",
#     optimizer = optimizer_sgd(lr = initial_lrate, momentum = 0.6, nesterov = TRUE),
#    #optimizer = optimizer_rmsprop(lr = 1e-4),
#     metrics = c("acc")
# )
#summary(network)
```

# a generator to generate image distortion so we can have a variety of training images in different orientaions, shapes, sizes etc.
```{r}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 5,
  width_shift_range = 0.1,
  height_shift_range = 0.05,
  #shear_range = 0.2,
  brightness_range = list(0.5, 2),
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest",
  validation_split = 0.2
)

```

```{r}
#train_datagen <- image_data_generator(rescale = 1/255)
#validation_datagen <- image_data_generator(rescale = 1/255)
batchSize = 10
generator_fun <- function(traindir, type){
  flow_images_from_directory(
    traindir,
    datagen,
    target_size = c(48, 48),
    batch_size = batchSize,
    class_mode = "categorical",
    subset = type
    #save_to_dir='aug',
    #save_prefix='aug',
    #save_format='jpg'
  )
}

train_generator = sapply(dirlist[,1], function (x) generator_fun(x,"training"))
#validation_generator = sapply(dirlist[,1], function (x) generator_fun(x,"validation"))
# batch <- generator_next(train_generator)
# str(batch)
```

```{r}
# validation_generator <- flow_images_from_directory(
#     validation_dir,
#     datagen,
#     target_size = c(48, 48),
#     batch_size = batchSize,
#     class_mode = "categorical"
# )
# batch <- generator_next(validation_generator)
# str(batch)
```

```{r}
initial_lrate = 1e-3
min_lrate = 1e-5

schedule <- function(epoch, current_lrate){
  drop_rate = 0.5
  lrate = current_lrate
  if (epoch > 0 && epoch %% 10 == 0){
    lrate = current_lrate * drop_rate
  }
  if (lrate < min_lrate){
    lrate = min_lrate
  }
  return (lrate)
}

lr_schedule = callback_learning_rate_scheduler(schedule)


for (i in 1:length(train_generator)){
#  for (i in 1:1){

  
  network <- keras_model_sequential() %>%
    layer_conv_2d(filters = 32, kernel_size = c(7, 7), activation = "relu",
    input_shape = c(48, 48, 3)) %>%
    layer_max_pooling_2d(pool_size = c(2, 2)) %>%
    layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
    layer_max_pooling_2d(pool_size = c(2, 2)) %>%
    layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
    layer_flatten() %>%
    layer_dense(units = 256, activation = "relu") %>%
    layer_dropout(0.5) %>%
    layer_dense(units = 128, activation = "relu") %>%
    layer_dropout(0.5) %>%
    layer_dense(units = 6, activation = "softmax")
  
  
  network %>% compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_sgd(lr = initial_lrate, momentum = 0.6, nesterov = TRUE),
   #optimizer = optimizer_rmsprop(lr = 1e-4),
    metrics = c("acc")
  )
  
  if (file.exists(paste0("lisa_TL_train_sampling_",i,".hdf5"))){
    network <- load_model_hdf5(paste0("lisa_TL_train_sampling_",i,".hdf5"))
  }
  epochsNum = 50
  
  # define the checkpoint
  filename = paste0("lisa_TL_train_sampling_CP_",i,".hdf5")
  checkpoint = callback_model_checkpoint(filename, monitor='loss', verbose=1, save_best_only=TRUE, mode='min')
  
  # train model
  history <- network %>% fit_generator(
      train_generator[[i]],
      steps_per_epoch = as.integer(train_generator[[i]]$n/batchSize),
      epochs = epochsNum,
      #validation_data = validation_generator[[i]],
      #validation_steps = as.integer(validation_generator[[i]]$n/batchSize),
      callbacks = list(checkpoint, lr_schedule)
  )
  
  # now save CNN models
  #plot(history)
  network %>% save_model_hdf5(paste0("lisa_TL_train_sampling_",i,".hdf5"))
}
```

```{r}

library(keras)
NumofModels = 7

batch_size_test = 12
test_datagen <- image_data_generator(rescale = 1/255)
test_generator <- flow_images_from_directory(
  test_dir,
  test_datagen,
  target_size = c(48, 48),
  batch_size = batch_size_test,
  class_mode = "categorical",
  shuffle = FALSE
)

#calculate ensemble
results.prob = array(0,c((test_generator$n%/%batch_size_test)*batch_size_test,length(tlclass)))
results.total = array(0,c((test_generator$n%/%batch_size_test)*batch_size_test,length(tlclass)))
for (i in 1:NumofModels){
  network <- load_model_hdf5(paste0("lisa_TL_train_sampling_",i,".hdf5"))
  results.temp <- predict_generator(network, test_generator, steps = test_generator$n%/%batch_size_test)
  results.total=results.total+results.temp
  if (i == 1){
    results.prob=results.temp
  }else{
    results.prob=rbind(results.prob,results.temp)
  }
  paste0("Iterations ", i)
  freeMemory=gc()
}
#results.eval <- evaluate_generator(network, test_generator, steps = length(test_generator$labels))

results.predlabel <- apply(results.total,1,which.max) - 1
table(results.predlabel, test_generator$labels)

# calculate cumulative
results.prob.accumulated = array(0,c((test_generator$n%/%batch_size_test)*batch_size_test,length(tlclass)))
for (i in 1:NumofModels){
  results.prob.accumulated = results.prob.accumulated + results.prob[(test_generator$n*(i-1)+1):(test_generator$n*i),]
  results.predlabel.accumulated <- apply(results.prob.accumulated,1,which.max) - 1
  if (i == 1){
    acc.accumulated = sum(results.predlabel.accumulated==test_generator$labels)/test_generator$n
  }else{
    acc.accumulated = rbind(acc.accumulated,sum(results.predlabel.accumulated==test_generator$labels)/test_generator$n)
  }
}
acc.accumulated

#first classifier
results.predlabel.first <- apply(results.prob[1:test_generator$n,],1,which.max) - 1
table(results.predlabel.first, test_generator$labels)

save.image(file = "lisa_traffic_light_sampling.dataVariables.RData")
#results.eval
```